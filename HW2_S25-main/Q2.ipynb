{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()\n",
    "using LinearAlgebra, Plots\n",
    "import ForwardDiff as FD\n",
    "import MeshCat as mc \n",
    "using JLD2\n",
    "using Test\n",
    "using Random\n",
    "include(joinpath(@__DIR__,\"utils/cartpole_animation.jl\"))\n",
    "include(joinpath(@__DIR__,\"utils/basin_of_attraction.jl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdff41f3",
   "metadata": {},
   "source": [
    "## Note: \n",
    "\n",
    "Some of the cells below will have multiple outputs (plots and animations), it can be easier to see everything if you do `Cell -> All Output -> Toggle Scrolling`, so that it simply expands the output area to match the size of the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c9cfe",
   "metadata": {},
   "source": [
    "# Q2: LQR for nonlinear systems (40 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3c0cd",
   "metadata": {},
   "source": [
    "## Linearization warmup \n",
    "Before we apply LQR to nonlinear systems, we are going to treat our linear system as if it's nonlinear. Specifically, we are going to \"approximate\" our linear system with a first-order Taylor series, and define a new set of $(\\Delta x, \\Delta u)$ coordinates. Since our dynamics are linear, this approximation is exact, allowing us to check that we set up the problem correctly. \n",
    "\n",
    "First, assume our discrete time dynamics are the following:\n",
    "\n",
    "$$ x_{k+1} = f(x_k,u_k) $$\n",
    "\n",
    "And we are going to linearize about a reference trajectory $\\bar{x}_{1:N}, \\bar{u}_{1:N-1}$. From here, we can define our delta's accordingly:\n",
    "\n",
    "$$ \\begin{align} x_k &= \\bar{x}_k + \\Delta x_k \\\\ u_k &= \\bar{u}_k + \\Delta u_k \\end{align}$$  \n",
    "\n",
    "Next, we are going to approximate our discrete time dynamics function with the following first order Taylor series:\n",
    "\n",
    "$$ \n",
    "x_{k+1} \\approx f(\\bar{x}_k, \\bar{u}_k) + \\bigg[\\frac{\\partial f}{\\partial x} \\bigg|_{\\bar{x}_k, \\bar{u}_k}  \\bigg](x_k - \\bar{x}_k) + \\bigg[\\frac{\\partial f}{\\partial u} \\bigg|_{\\bar{x}_k, \\bar{u}_k}  \\bigg](u_k - \\bar{u}_k)\n",
    "$$\n",
    "\n",
    "Which we can substitute in our delta notation to get the following:\n",
    "\n",
    "$$ \n",
    "\\bar{x}_{k+1} + \\Delta x_{k+1} \\approx f(\\bar{x}_k, \\bar{u}_k) + \\bigg[\\frac{\\partial f}{\\partial x} \\bigg|_{\\bar{x}_k, \\bar{u}_k}  \\bigg]\\Delta x_k + \\bigg[\\frac{\\partial f}{\\partial u} \\bigg|_{\\bar{x}_k, \\bar{u}_k}  \\bigg] \\Delta u_k\n",
    "$$\n",
    "\n",
    "If the trajectory $\\bar{x},\\bar{u}$ is dynamically feasible (meaning $\\bar{x}_{k+1} = f(\\bar{x}_k, \\bar{u}_k)$), then we can cancel these equivalent terms on each side of the above equation, resulting in the following:\n",
    "\n",
    "$$ \n",
    " \\Delta x_{k+1} \\approx  \\bigg[\\frac{\\partial f}{\\partial x} \\bigg|_{\\bar{x}_k, \\bar{u}_k}  \\bigg]\\Delta x_k + \\bigg[\\frac{\\partial f}{\\partial u} \\bigg|_{\\bar{x}_k, \\bar{u}_k}  \\bigg] \\Delta u_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f744af19",
   "metadata": {},
   "source": [
    "## Cartpole \n",
    "We are now going to look at two different applications of LQR to the nonlinear cartpole system. Given the following description of the cartpole:\n",
    "<div>\n",
    "<img src=\"attachment:cartpole.png\" width=\"300\"/>\n",
    "</div>\n",
    "(if this image doesn't show up, check out `cartpole.png`)\n",
    "\n",
    "\n",
    "with a cart position $p$ and pole angle $\\theta$. We are first going to linearize the nonlinear discrete dynamics of this system about the point where $p = 0$, and $\\theta = 0$ (no velocities), and use an infinite horizon LQR controller about this linearized state to stabilize the cartpole about this goal state.  The dynamics of the cartpole are parametrized by the mass of the cart, the mass of the pole, and the length of the pole. To simulate a \"sim to real gap\", we are going to design our controllers around an estimated set of problem parameters `params_est`, and simulate our system with a different set of problem parameters `params_real`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a01683",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "continuous time dynamics for a cartpole, the state is \n",
    "x = [p, θ, ṗ, θ̇]\n",
    "where p is the horizontal position, and θ is the angle\n",
    "where θ = 0 has the pole hanging down, and θ = 180 is up.\n",
    "\n",
    "The cartpole is parametrized by a cart mass `mc`, pole \n",
    "mass `mp`, and pole length `l`. These parameters are loaded \n",
    "into a `params::NamedTuple`. We are going to design the\n",
    "controller for a estimated `params_est`, and simulate with \n",
    "`params_real`. \n",
    "\"\"\"\n",
    "function dynamics(params::NamedTuple, x::Vector, u)\n",
    "    # cartpole ODE, parametrized by params. \n",
    "\n",
    "    # cartpole physical parameters \n",
    "    mc, mp, l = params.mc, params.mp, params.l\n",
    "    g = 9.81\n",
    "    \n",
    "    q = x[1:2]\n",
    "    qd = x[3:4]\n",
    "\n",
    "    s = sin(q[2])\n",
    "    c = cos(q[2])\n",
    "\n",
    "    H = [mc+mp mp*l*c; mp*l*c mp*l^2]\n",
    "    C = [0 -mp*qd[2]*l*s; 0 0]\n",
    "    G = [0, mp*g*l*s]\n",
    "    B = [1, 0]\n",
    "\n",
    "    qdd = -H\\(C*qd + G - B*u[1])\n",
    "    return [qd;qdd]\n",
    "\n",
    "end\n",
    "\n",
    "# true nonlinear dynamics of the system\n",
    "# if I want to simulate, this is what I do\n",
    "function rk4(params::NamedTuple, x::Vector,u,dt::Float64)\n",
    "    # vanilla RK4\n",
    "    k1 = dt*dynamics(params, x, u)\n",
    "    k2 = dt*dynamics(params, x + k1/2, u)\n",
    "    k3 = dt*dynamics(params, x + k2/2, u)\n",
    "    k4 = dt*dynamics(params, x + k3, u)\n",
    "    return x + (1/6)*(k1 + 2*k2 + 2*k3 + k4)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abddd16",
   "metadata": {},
   "source": [
    "## Part A: Infinite Horizon LQR about an equilibrium (10 pts)\n",
    "Here we are going to solve for the infinite horizon LQR gain, and use it to stabilize the cartpole about the unstable equilibrium. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"LQR about eq\" begin\n",
    "    \n",
    "    # states and control sizes \n",
    "    nx = 4 \n",
    "    nu = 1 \n",
    "    \n",
    "    # desired x and g (linearize about these)\n",
    "    xgoal = [0, pi, 0, 0]\n",
    "    ugoal = [0]\n",
    "    \n",
    "    # initial condition (slightly off of our linearization point)\n",
    "    x0 = [0, pi, 0, 0] + [1.5, deg2rad(-20), .3, 0]\n",
    "    \n",
    "    # simulation size \n",
    "    dt = 0.1 \n",
    "    tf = 5.0 \n",
    "    t_vec = 0:dt:tf\n",
    "    N = length(t_vec)\n",
    "    X = [zeros(nx) for i = 1:N]\n",
    "    X[1] = x0 \n",
    "    \n",
    "    # estimated parameters (design our controller with these)\n",
    "    params_est = (mc = 1.0, mp = 0.2, l = 0.5)\n",
    "    \n",
    "    # real paremeters (simulate our system with these)\n",
    "    params_real = (mc = 1.2, mp = 0.16, l = 0.55)\n",
    "    \n",
    "    # TODO: solve for the infinite horizon LQR gain Kinf\n",
    "    \n",
    "    # cost terms \n",
    "    Q = diagm([1,1,.05,.1])\n",
    "    R = 0.1*diagm(ones(nu))\n",
    "    \n",
    "    Kinf = zeros(1,4)\n",
    "    \n",
    "    # TODO: simulate this controlled system with rk4(params_real, ...)\n",
    "        \n",
    "\n",
    "    \n",
    "    # ---------------tests and plots/animations---------------\n",
    "    @test X[1] == x0 \n",
    "    @test norm(X[end])>0\n",
    "    @test norm(X[end] - xgoal) < 0.1 \n",
    "    \n",
    "    Xm = hcat(X...)\n",
    "    display(plot(t_vec,Xm',title = \"cartpole\",\n",
    "                 xlabel = \"time(s)\", ylabel = \"x\",\n",
    "                 label = [\"p\" \"θ\" \"ṗ\" \"θ̇\"]))\n",
    "    \n",
    "    # animation stuff\n",
    "    display(animate_cartpole(X, dt))\n",
    "    # ---------------tests and plots/animations---------------\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0e3a61",
   "metadata": {},
   "source": [
    "## Part B: Infinite horizon LQR basin of attraction (5 pts)\n",
    "\n",
    "In part A we built a controller for the cartpole that was based on a linearized version of the system dynamics. This linearization took place at the `(xgoal, ugoal)`, so we should only really expect this model to be accurate if we are close to this linearization point (think small angle approximation). As we get further from the goal state, our linearized model is less and less accurate, making the performance of our controller suffer. At a certain point, the controller is unable to stabilize the cartpole due to this model mismatch. \n",
    "\n",
    "To demonstrate this, you are now being asked to take the same controller you used above, and try it for a range of initial conditions. For each of these simulations, you will determine if the controller was able to stabilize the cartpole. From here, you will plot the successes and failures on a plot and visualize a \"basin of attraction\", that is, a region of the state space where we expect our controller to stabilize the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_initial_conditions()\n",
    "    # create a span of initial configurations \n",
    "    M=20\n",
    "    ps = LinRange(-7, 7, M)\n",
    "    thetas = LinRange(deg2rad(180-60), deg2rad(180+60), M)\n",
    "    \n",
    "    initial_conditions = []\n",
    "    \n",
    "    for p in ps \n",
    "        for theta in thetas \n",
    "            push!(initial_conditions, [p, theta, 0, 0.0])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return initial_conditions, ps, thetas\n",
    "end\n",
    "\n",
    "function check_simulation_convergence(params_real, initial_condition, Kinf, xgoal, N, dt)\n",
    "    \"\"\"\n",
    "    args\n",
    "        params_real: named tuple with model dynamics parametesr \n",
    "        initial_condition: X0, length 4 vector \n",
    "        Kinf: IHLQR feedback gain \n",
    "        xgoal: desired state, length 4 vector \n",
    "        N: number of simulation steps\n",
    "        dt: time between steps \n",
    "    \n",
    "    return\n",
    "        is_controlled: bool \n",
    "    \"\"\"\n",
    "\n",
    "    x0= 1 * initial_condition \n",
    "\n",
    "    is_controlled = false\n",
    "    \n",
    "    # TODO: simulate the closed-loop (controlled) cartpole starting at the initial condition \n",
    "    \n",
    "    # for some of the unstable initial conditions, the integrator will \"blow up\", in order to \n",
    "    # catch these errors, you can stop the sim and return is_controlled = false if norm(x) > 100 \n",
    "    \n",
    "    # you should consider the simulation to have been successfuly controlled if the \n",
    "    # L2 norm of |xfinal - xgoal| < 0.1. (norm(xfinal-xgoal) < 0.1 in Julia)\n",
    "    \n",
    "\n",
    "    return is_controlled \n",
    "end\n",
    "\n",
    "let \n",
    "    \n",
    "    nx = 4 \n",
    "    nu = 1 \n",
    "    xgoal = [0, pi, 0, 0]\n",
    "    ugoal = [0]\n",
    "    dt = 0.1 \n",
    "    tf = 5.0 \n",
    "    t_vec = 0:dt:tf\n",
    "    N = length(t_vec)\n",
    "    \n",
    "    \n",
    "    # estimated parameters (design our controller with these)\n",
    "    params_est = (mc = 1.0, mp = 0.2, l = 0.5)\n",
    "    \n",
    "    # real paremeters (simulate our system with these)\n",
    "    params_real = (mc = 1.2, mp = 0.16, l = 0.55)\n",
    "    \n",
    "    # TODO: solve for the infinite horizon LQR gain Kinf\n",
    "    # this is the same controller as part B\n",
    "\n",
    "    # cost terms\n",
    "    Q = diagm([1,1,.05,.1])\n",
    "    R = 0.1*diagm(ones(nu))\n",
    "\n",
    "    Kinf = zeros(1,4)\n",
    "    \n",
    "    # create the set of initial conditions we want to test for convergence\n",
    "    initial_conditions, ps, thetas = create_initial_conditions()\n",
    "    \n",
    "    convergence_list = [] \n",
    "    \n",
    "    for initial_condition in initial_conditions\n",
    "\n",
    "        convergence = check_simulation_convergence(params_real,\n",
    "                                                   initial_condition,\n",
    "                                                   Kinf, xgoal, N, dt)\n",
    "        \n",
    "        push!(convergence_list, convergence)\n",
    "    end\n",
    "    \n",
    "    plot_basin_of_attraction(initial_conditions, convergence_list, ps, rad2deg.(thetas))\n",
    "    \n",
    "\n",
    "    # -------------tests------------------\n",
    "    @test sum(convergence_list) < 190 \n",
    "    @test sum(convergence_list) > 180 \n",
    "    @test length(convergence_list) == 400 \n",
    "    @test length(initial_conditions) == 400\n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834556e2",
   "metadata": {},
   "source": [
    "## Part C: Infinite horizon LQR cost tuning (5 pts)\n",
    "\n",
    "We are now going to tune the LQR cost to satisfy our following performance requirement:\n",
    "\n",
    "$\\|x(5.0) - x_{\\text{goal}}\\|_2=$`norm(X[N] - xgoal) < 0.1` \n",
    "\n",
    "which says that the L2 norm of the state at 5 seconds (last timestep in our simulation) should be less than 0.1. We are also going to have to deal with the following actuator limits: $-3 \\leq u \\leq 3$. You won't be able to directly reason about this actuator limit in our LQR controller, but we can tune our cost function to avoid saturating the actuators (reaching the actuator limits) for too long. Here are our suggestions for tuning successfully:\n",
    "\n",
    "1. First, adjust the values in Q and R to find a controller that stabilizes the cartpole. The key here is tuning our cost to keep the control away from the actuator limits for too long. \n",
    "2. Now that you can stabilize the system, the next step is to tune the values in Q and R accomplish our performance goal of `norm(X[N] - xgoal) < 0.1`. Think about the individual values in Q, and which states we really want to penalize. The positions $(p,\\, \\theta)$ should be penalized differently than the velocities $(\\dot{p}, \\,\\dot{\\theta})$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17813ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"LQR about eq\" begin\n",
    "    \n",
    "    # states and control sizes \n",
    "    nx = 4 \n",
    "    nu = 1 \n",
    "    \n",
    "    # desired x and g (linearize about these)\n",
    "    xgoal = [0, pi, 0, 0]\n",
    "    ugoal = [0]\n",
    "    \n",
    "    # initial condition (slightly off of our linearization point)\n",
    "    x0 = [0, pi, 0, 0] + [0.5, deg2rad(-10), .3, 0]\n",
    "    \n",
    "    # simulation size \n",
    "    dt = 0.1 \n",
    "    tf = 5.0 \n",
    "    t_vec = 0:dt:tf\n",
    "    N = length(t_vec)\n",
    "    X = [zeros(nx) for i = 1:N]\n",
    "    X[1] = x0 \n",
    "    \n",
    "    # estimated parameters (design our controller with these)\n",
    "    params_est = (mc = 1.0, mp = 0.2, l = 0.5)\n",
    "    \n",
    "    # real paremeters (simulate our system with these)\n",
    "    params_real = (mc = 1.2, mp = 0.16, l = 0.55)\n",
    "    \n",
    "    # TODO: solve for the infinite horizon LQR gain Kinf\n",
    "    \n",
    "    # cost terms\n",
    "    Q = diagm([1,1,.01,.01])\n",
    "    R = 1*diagm(ones(nu))\n",
    "\n",
    "    Kinf = zeros(1,4)\n",
    "    \n",
    "    # vector of length 1 vectors for our control\n",
    "    U = [[0.0] for i = 1:N-1]\n",
    "    \n",
    "    # TODO: simulate this controlled system with rk4(params_real, ...)\n",
    "    # TODO: make sure you clamp the control input with clamp.(U[i], -3.0, 3.0)\n",
    "  \n",
    "      \n",
    "    \n",
    "    \n",
    "    # ---------------tests and plots/animations---------------\n",
    "    @test X[1] == x0  # initial condition is used\n",
    "    @test norm(X[end])>0 # end is nonzero\n",
    "    @test norm(X[end] - xgoal) < 0.1 # within 0.1 of the goal \n",
    "    @test norm(vcat(U...), Inf) <= 3.0 # actuator limits are respected\n",
    "    \n",
    "    Xm = hcat(X...)\n",
    "    display(plot(t_vec,Xm',title = \"cartpole\",\n",
    "                 xlabel = \"time(s)\", ylabel = \"x\",\n",
    "                 label = [\"p\" \"θ\" \"ṗ\" \"θ̇\"]))\n",
    "    \n",
    "    # animation stuff\n",
    "    display(animate_cartpole(X, dt))\n",
    "    # ---------------tests and plots/animations---------------\n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c9c832",
   "metadata": {},
   "source": [
    "## Part D: TVLQR for trajectory tracking (15 pts)\n",
    "\n",
    "Here we are given a swingup trajectory that works for `params_est`, but will fail to work with `params_real`. To account for this sim to real gap, we are going to track this trajectory with a TVLQR controller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b97f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"track swingup\" begin \n",
    "    \n",
    "    # optimized trajectory we are going to try and track\n",
    "    DATA = load(joinpath(@__DIR__,\"swingup.jld2\"))\n",
    "    Xbar = DATA[\"X\"]\n",
    "    Ubar = DATA[\"U\"]\n",
    "    \n",
    "    # states and controls \n",
    "    nx = 4 \n",
    "    nu = 1 \n",
    "    \n",
    "    # problem size \n",
    "    dt = 0.05 \n",
    "    tf = 4.0 \n",
    "    t_vec = 0:dt:tf\n",
    "    N = length(t_vec)\n",
    "    \n",
    "    # states (initial condition of zeros)\n",
    "    X = [zeros(nx) for i = 1:N]\n",
    "    X[1] = [0, 0, 0, 0.0] \n",
    "    \n",
    "    # make sure we have the same initial condition \n",
    "    @assert norm(X[1] - Xbar[1]) < 1e-12\n",
    "    \n",
    "    # real and estimated params \n",
    "    params_est = (mc = 1.0, mp = 0.2, l = 0.5)\n",
    "    params_real = (mc = 1.2, mp = 0.16, l = 0.55)\n",
    "    \n",
    "    # TODO: design a time-varying LQR controller to track this trajectory \n",
    "    # use params_est for your control design, and params_real for the simulation\n",
    "    \n",
    "    # cost terms \n",
    "    Q = diagm([1,1,.05,.1])\n",
    "    Qf = 10*Q\n",
    "    R = 0.05*diagm(ones(nu))\n",
    "\n",
    "    # TODO: solve for tvlqr gains K\n",
    "\n",
    "    \n",
    "    \n",
    "    # TODO: simulate this controlled system with rk4(params_real, ...)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ---------------tests and plots/animations---------------\n",
    "    xn = X[N]\n",
    "    @test norm(xn)>0\n",
    "    @test 1e-6<norm(xn - Xbar[end])<.2\n",
    "    @test abs(abs(rad2deg(xn[2])) - 180) < 5 # within 5 degrees \n",
    "    \n",
    "    Xm = hcat(X...)\n",
    "    Xbarm = hcat(Xbar...)\n",
    "    plot(t_vec,Xbarm',ls=:dash, label = [\"p̄\" \"θ̄\" \"ṗ̄\" \"θ̇̄\"],lc = [:red :green :blue :black])\n",
    "    display(plot!(t_vec,Xm',title = \"Cartpole TVLQR (-- is reference)\",\n",
    "                 xlabel = \"time(s)\", ylabel = \"x\",\n",
    "                 label = [\"p\" \"θ\" \"ṗ\" \"θ̇\"],lc = [:red :green :blue :black]))\n",
    "    \n",
    "    # animation stuff\n",
    "    display(animate_cartpole(X, dt))\n",
    "    # ---------------tests and plots/animations---------------\n",
    "\n",
    "    \n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.7",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
